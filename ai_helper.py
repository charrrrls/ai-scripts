#!/usr/bin/env python3
"""
AIåŠ©æ‰‹æ ¸å¿ƒè„šæœ¬ - by é˜®é˜®
æä¾›AIè°ƒç”¨ã€å¯¹è¯ã€åšå®¢ç”Ÿæˆç­‰åŠŸèƒ½
"""

import os
import time
import threading
import tempfile
import base64
from datetime import datetime
from typing import Optional
import argparse
import re
from PIL import Image, ImageGrab
from rich_utils import (print_error, print_success, print_warning, print_info, print_progress,
                       display_ai_response, display_statistics, create_streaming_callback, rich_output)
from ai_client import get_client, AIClientError
from ai_config import get_config


class AIHelper:
    def __init__(self):
        self.client = get_client()
        self.config = get_config()
        self.config_dir = "/Users/leion/scripts/config"
        self.default_prompt_file = f"{self.config_dir}/default_prompt.txt"
        
    def get_default_prompt(self) -> str:
        """è·å–é»˜è®¤promptï¼Œä¼˜å…ˆä»é…ç½®æ–‡ä»¶è¯»å–"""
        try:
            if os.path.exists(self.default_prompt_file):
                with open(self.default_prompt_file, 'r', encoding='utf-8') as f:
                    content = f.read().strip()
                    # è·³è¿‡æ³¨é‡Šè¡Œ
                    lines = [line for line in content.split('\n') if not line.strip().startswith('#')]
                    prompt = '\n'.join(lines).strip()
                    if prompt:
                        return prompt
        except Exception as e:
            print_warning(f"è¯»å–é»˜è®¤prompté…ç½®å¤±è´¥: {e}")
        
        # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨æˆ–è¯»å–å¤±è´¥ï¼Œè¿”å›å†…ç½®é»˜è®¤prompt
        return """è¯·ä½œä¸ºä¸€ä¸ªä¸“ä¸šã€å‹å¥½çš„AIåŠ©æ‰‹å›ç­”ä»¥ä¸‹é—®é¢˜ã€‚è¦æ±‚ï¼š
1. å›ç­”å‡†ç¡®ã€è¯¦ç»†ä½†ç®€æ´ï¼Œä¸è¦æœ‰å¤ªå¤šçš„è§£é‡Šæ–‡å­—
2. å¦‚æœæ˜¯æŠ€æœ¯é—®é¢˜ï¼Œæä¾›å®ç”¨çš„å»ºè®®
3. ä½¿ç”¨ä¸­æ–‡å›ç­”
4. ä¿æŒä¸“ä¸šä½†å‹å¥½çš„è¯­è°ƒ"""

    def _show_spinner(self, message: str = "æ€è€ƒä¸­") -> None:
        """æ˜¾ç¤ºåŠ è½½åŠ¨ç”»"""
        chars = "â ‹â ™â ¹â ¸â ¼â ´â ¦â §â ‡â "
        i = 0
        try:
            while True:
                colored_print(f"\r{message} {chars[i % len(chars)]}", MessageType.PROGRESS, prefix="", end="", flush=True)
                time.sleep(0.1)
                i += 1
        except KeyboardInterrupt:
            colored_print(f"\r{' ' * (len(message) + 2)}\r", MessageType.NORMAL, prefix="", end="")

    def _typewriter_output(self, text: str, delay: float = 0.02) -> None:
        """æ‰“å­—æœºæ•ˆæœè¾“å‡º"""
        try:
            for char in text:
                colored_print(char, MessageType.NORMAL, prefix="", end="", flush=True)
                if char in "ã€‚ï¼Ÿï¼.?!":
                    time.sleep(delay * 3)
                elif char in "ï¼Œï¼›,;":
                    time.sleep(delay * 2)
                else:
                    time.sleep(delay)
        except KeyboardInterrupt:
            print_warning("\nè¾“å‡ºè¢«ä¸­æ–­")
            
    def call_ai(self, prompt: str, max_tokens: int = 2000, temperature: float = 0.7) -> Optional[str]:
        """è°ƒç”¨AI API"""
        try:
            return self.client.chat(prompt, max_tokens=max_tokens, temperature=temperature)
        except AIClientError as e:
            print_error(f"AIè°ƒç”¨å¤±è´¥: {e}")
            return None
        except Exception as e:
            print_error(f"æœªçŸ¥é”™è¯¯: {e}")
            return None
    
    def chat(self, question: str, use_stream: bool = False, custom_prompt: str = None) -> None:
        """é€šç”¨AIå¯¹è¯"""
        if not question:
            print_info("Usage: python ai_helper.py chat \"your question\"")
            return

        print_info(f"Question: {question}\n")

        # ä½¿ç”¨è‡ªå®šä¹‰promptæˆ–é»˜è®¤prompt
        if custom_prompt:
            print_info(f"ä½¿ç”¨è‡ªå®šä¹‰ Prompt: {custom_prompt[:50]}{'...' if len(custom_prompt) > 50 else ''}")
            general_prompt = f"{custom_prompt}\n\né—®é¢˜ï¼š{question}"
        else:
            default_prompt = self.get_default_prompt()
            general_prompt = f"{default_prompt}\n\né—®é¢˜ï¼š{question}"

        # ä¿®æ”¹é€»è¾‘ï¼šå¦‚æœæ˜ç¡®æŒ‡å®šuse_streamï¼Œåˆ™å¼ºåˆ¶ä½¿ç”¨æµå¼è¾“å‡º
        # å¦åˆ™æ ¹æ®é…ç½®å†³å®š
        should_use_stream = use_stream if use_stream else (
            self.config.is_streaming_enabled() and 
            self.config.get_scenario_config("chat").get("stream", False)
        )
        
        if should_use_stream:
            self._chat_with_stream(general_prompt)
        else:
            self._chat_without_stream(general_prompt)

    def _chat_without_stream(self, prompt: str) -> None:
        """æ‰¹é‡æ¨¡å¼å¯¹è¯ - Richå¢å¼ºç‰ˆ"""
        print_info("GLM-4 æ­£åœ¨æ€è€ƒ...")
        start_time = time.time()
        
        result = self.call_ai(prompt, 1500, 0.7)
        
        end_time = time.time()
        duration = end_time - start_time

        if result:
            # ä½¿ç”¨Richæ˜¾ç¤ºAIå›å¤
            display_ai_response(result, "AI å›å¤")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_chars = len(result)
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', result))
            english_chars = total_chars - chinese_chars
            total_tokens_estimate = chinese_chars // 2 + english_chars // 4
            
            stats = {
                "chars": total_chars,
                "tokens": total_tokens_estimate,
                "duration": duration
            }
            display_statistics(stats)
        else:
            print_error("è·å–AIå›ç­”å¤±è´¥")

    def _chat_with_stream(self, prompt: str) -> None:
        """æµå¼æ¨¡å¼å¯¹è¯ - Richå¢å¼ºç‰ˆï¼Œå¹¶è¡Œä¼˜åŒ–"""
        
        # ç»Ÿè®¡å˜é‡
        api_start_time = None
        first_token_time = None
        total_chars = 0
        total_tokens_estimate = 0
        full_response = ""
        streaming_callback = None
        
        # å…±äº«å˜é‡ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡
        rich_ready = threading.Event()
        api_ready = threading.Event()
        
        try:
            def init_rich():
                """Richåˆå§‹åŒ–çº¿ç¨‹"""
                nonlocal streaming_callback
                streaming_callback = create_streaming_callback("AI å›å¤")
                rich_ready.set()  # é€šçŸ¥Richåˆå§‹åŒ–å®Œæˆ
            
            def on_chunk(chunk: str):
                nonlocal total_chars, total_tokens_estimate, full_response, first_token_time
                
                # è®°å½•é¦–ä¸ªè¯çš„å“åº”æ—¶é—´ (TTFT - Time To First Token)
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                
                # ç´¯ç§¯å®Œæ•´å“åº”
                full_response += chunk
                
                # æ¸…ç†chunkï¼Œç§»é™¤ANSIé¢œè‰²ä»£ç è¿›è¡Œç»Ÿè®¡
                clean_chunk = re.sub(r'\x1b\[[0-9;]*m', '', chunk)
                total_chars += len(clean_chunk)
                # ç²—ç•¥ä¼°ç®—tokenæ•°ï¼ˆä¸­æ–‡çº¦2å­—ç¬¦=1tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦=1tokenï¼‰
                chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', clean_chunk))
                english_chars = len(clean_chunk) - chinese_chars
                total_tokens_estimate += chinese_chars // 2 + english_chars // 4
                
                # ç­‰å¾…Richåˆå§‹åŒ–å®Œæˆå†æ˜¾ç¤º
                rich_ready.wait()
                streaming_callback(chunk)
                time.sleep(self.config.stream_delay)

            # å¹¶è¡Œå¯åŠ¨ï¼šRichåˆå§‹åŒ–
            rich_thread = threading.Thread(target=init_rich)
            rich_thread.start()
            
            # ç«‹å³å‘é€APIè¯·æ±‚ï¼ˆä¸ç­‰Richåˆå§‹åŒ–ï¼‰
            api_start_time = time.time()
            result = self.client.chat_with_scenario(prompt, "chat", on_chunk)
            
            # ç­‰å¾…Richçº¿ç¨‹å®Œæˆ
            rich_thread.join()
            
            # å®Œæˆæµå¼è¾“å‡º
            if streaming_callback:
                streaming_callback.finish()
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            duration = end_time - api_start_time if api_start_time else 0
            chars_per_sec = total_chars / duration if duration > 0 else 0
            tokens_per_sec = total_tokens_estimate / duration if duration > 0 else 0
            
            # è®¡ç®—é¦–è¯å“åº”æ—¶é—´ (TTFT)
            ttft = (first_token_time - api_start_time) if (first_token_time and api_start_time) else 0
            
            if result:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å«é¦–è¯å“åº”æ—¶é—´
                stats = {
                    "chars": total_chars,
                    "tokens": total_tokens_estimate,
                    "speed": chars_per_sec,
                    "token_speed": tokens_per_sec,
                    "ttft": ttft,  # Time To First Token
                    "duration": duration
                }
                display_statistics(stats)
            else:
                print_error("è·å–AIå›ç­”å¤±è´¥")

        except AIClientError as e:
            print_error(f"AIå¯¹è¯å¤±è´¥: {e}")
        except Exception as e:
            print_error(f"æœªçŸ¥é”™è¯¯: {e}")
    
    def generate_commit_message(self, changes_summary: str) -> Optional[str]:
        """æ ¹æ®æ–‡ä»¶æ›´æ”¹å†…å®¹ç”Ÿæˆcommitä¿¡æ¯"""
        if not changes_summary:
            return None

        try:
            result = self.client.generate_commit_message(changes_summary)
            if result:
                # æ¸…ç†è¿”å›çš„å†…å®¹
                commit_msg = result.strip().replace('\n', ' ').replace('\r', '')
                # ç§»é™¤å¯èƒ½çš„å¼•å·
                commit_msg = commit_msg.strip('"\'')
                return commit_msg
        except AIClientError as e:
            print_error(f"ç”Ÿæˆcommitä¿¡æ¯å¤±è´¥: {e}")
        except Exception as e:
            print_error(f"æœªçŸ¥é”™è¯¯: {e}")

        return None

    def generate_blog_article(self, title: str) -> Optional[str]:
        """ç”Ÿæˆåšå®¢æ–‡ç« ç»“æ„"""
        if not title:
            print_error("é”™è¯¯ï¼šç¼ºå°‘æ–‡ç« æ ‡é¢˜")
            return None

        # è¯»å–Claudeé…ç½®
        claude_config = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯åšå®¢å†™ä½œåŠ©æ‰‹ã€‚"
        try:
            with open("/Users/leion/.claude/CLAUDE.md", "r", encoding="utf-8") as f:
                claude_config = f.read()
                print_info("å·²è¯»å–Claudeé…ç½®æ–‡ä»¶")
        except FileNotFoundError:
            print_warning("æœªæ‰¾åˆ°~/.claude/CLAUDE.mdé…ç½®æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
            
        print_progress("æ­£åœ¨ç”Ÿæˆåšå®¢æ–‡ç« ç»“æ„...")
        print_info(f"æ ‡é¢˜: {title}")
        print_progress("è¯·ç¨ç­‰ï¼ŒGLM-4æ­£åœ¨ä¸ºæ‚¨åˆ›ä½œ...")

        try:
            result = self.client.generate_blog_article(title, claude_config)
            if result:
                print_success("AIæ–‡ç« ç»“æ„ç”ŸæˆæˆåŠŸï¼")
                return result
        except AIClientError as e:
            print_error(f"AIç”Ÿæˆå¤±è´¥: {e}")
        except Exception as e:
            print_error(f"æœªçŸ¥é”™è¯¯: {e}")

        print_warning("AIç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿...")
        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        return f"""---
title: "{title}"
date: {current_time}
tags: [æŠ€æœ¯åˆ†äº«]
categories: [ä¸ªäººç»å†]
description: "å…³äº{title}çš„æŠ€æœ¯åˆ†äº«"
---

## ç®€ä»‹

## ä¸»è¦å†…å®¹

## å®è·µåº”ç”¨

## æ€»ç»“
"""

    def get_interactive_input(self) -> str:
        """äº¤äº’æ¨¡å¼è·å–ç”¨æˆ·è¾“å…¥"""
        print_info("=== äº¤äº’æ¨¡å¼ ===")
        print_info("è¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼ˆæ”¯æŒå¤šè¡Œï¼Œè¾“å…¥ 'END' ç»“æŸï¼‰:")
        print_info("æç¤ºï¼šæ­¤æ¨¡å¼æ”¯æŒä»»ä½•ç‰¹æ®Šå­—ç¬¦ï¼ŒåŒ…æ‹¬å¼•å·ã€æ‹¬å·ç­‰")
        rich_output.console.print("[dim]" + "-" * 50 + "[/]")

        lines = []
        while True:
            try:
                line = input()
                if line.strip().upper() == 'END':
                    break
                lines.append(line)
            except KeyboardInterrupt:
                print_warning("\nè¾“å…¥è¢«å–æ¶ˆ")
                return ""
            except EOFError:
                break

        question = '\n'.join(lines).strip()
        if question:
            rich_output.console.print("[dim]" + "-" * 50 + "[/]")
            print_info(f"æ‚¨çš„é—®é¢˜å·²æ¥æ”¶ï¼Œå…± {len(question)} ä¸ªå­—ç¬¦")

        return question

    def read_prompt_from_file(self, filepath: str) -> str:
        """ä»æ–‡ä»¶è¯»å–è‡ªå®šä¹‰prompt"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            if content:
                print_info(f"å·²ä»æ–‡ä»¶ {filepath} è¯»å– Promptï¼Œå…± {len(content)} ä¸ªå­—ç¬¦")
                return content
            else:
                print_warning(f"Promptæ–‡ä»¶ {filepath} ä¸ºç©º")
                return ""

        except FileNotFoundError:
            print_error(f"Promptæ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return ""
        except Exception as e:
            print_error(f"è¯»å–Promptæ–‡ä»¶å¤±è´¥: {e}")
            return ""

    def read_question_from_file(self, filepath: str) -> str:
        """ä»æ–‡ä»¶è¯»å–é—®é¢˜"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read().strip()

            if content:
                print_info(f"å·²ä»æ–‡ä»¶ {filepath} è¯»å–é—®é¢˜ï¼Œå…± {len(content)} ä¸ªå­—ç¬¦")
                return content
            else:
                print_warning(f"æ–‡ä»¶ {filepath} ä¸ºç©º")
                return ""

        except FileNotFoundError:
            print_error(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
            return ""
        except Exception as e:
            print_error(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return ""

    def get_clipboard_image(self) -> Optional[str]:
        """ä»å‰ªè´´æ¿è·å–å›¾ç‰‡å¹¶è½¬æ¢ä¸ºbase64"""
        try:
            # å°è¯•ä»å‰ªè´´æ¿è·å–å›¾ç‰‡
            clipboard_image = ImageGrab.grabclipboard()
            
            if clipboard_image is None:
                return None
            
            if not isinstance(clipboard_image, Image.Image):
                return None
            
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶å¹¶è½¬æ¢ä¸ºbase64
            with tempfile.NamedTemporaryFile(suffix='.png', delete=False) as temp_file:
                clipboard_image.save(temp_file.name, 'PNG')
                temp_path = temp_file.name
            
            # è¯»å–å¹¶ç¼–ç ä¸ºbase64
            with open(temp_path, 'rb') as f:
                image_data = f.read()
                base64_image = base64.b64encode(image_data).decode('utf-8')
            
            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            os.unlink(temp_path)
            
            return base64_image
            
        except Exception as e:
            print_error(f"è·å–å‰ªè´´æ¿å›¾ç‰‡å¤±è´¥: {e}")
            return None

    def chat_with_image(self, question: str, custom_prompt: str = None) -> None:
        """å¸¦å›¾ç‰‡çš„AIå¯¹è¯"""
        if not question:
            print_info("Usage: python ai_helper.py chat --image \"describe this image\"")
            return

        print_info("ğŸ–¼ï¸ æ­£åœ¨æ£€æµ‹å‰ªè´´æ¿å›¾ç‰‡...")
        
        # è·å–å‰ªè´´æ¿å›¾ç‰‡
        base64_image = self.get_clipboard_image()
        if not base64_image:
            print_error("å‰ªè´´æ¿ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ï¼è¯·å…ˆæˆªå›¾æˆ–å¤åˆ¶å›¾ç‰‡ã€‚")
            return
        
        print_success("âœ… å·²è·å–å‰ªè´´æ¿å›¾ç‰‡")
        print_info(f"Question: {question}\n")

        # ä½¿ç”¨è‡ªå®šä¹‰promptæˆ–é»˜è®¤prompt
        if custom_prompt:
            print_info(f"ä½¿ç”¨è‡ªå®šä¹‰ Prompt: {custom_prompt[:50]}{'...' if len(custom_prompt) > 50 else ''}")
            general_prompt = f"{custom_prompt}\n\né—®é¢˜ï¼š{question}"
        else:
            default_prompt = self.get_default_prompt()
            general_prompt = f"{default_prompt}\n\né—®é¢˜ï¼š{question}"

        # è§†è§‰åˆ†æä½¿ç”¨æµå¼è¾“å‡º
        should_use_stream = (
            self.config.is_streaming_enabled() and 
            self.config.get_scenario_config("vision").get("stream", True)
        )
        
        if should_use_stream:
            self._chat_with_vision_stream(general_prompt, base64_image)
        else:
            self._chat_with_vision_batch(general_prompt, base64_image)
    
    def _chat_with_vision_stream(self, prompt: str, image_base64: str) -> None:
        """æµå¼æ¨¡å¼è§†è§‰å¯¹è¯ - Richå¢å¼ºç‰ˆ"""
        
        # ç»Ÿè®¡å˜é‡
        api_start_time = None
        first_token_time = None
        total_chars = 0
        total_tokens_estimate = 0
        full_response = ""
        streaming_callback = None
        
        # å…±äº«å˜é‡ï¼Œç”¨äºçº¿ç¨‹é—´é€šä¿¡
        rich_ready = threading.Event()
        
        try:
            def init_rich():
                """Richåˆå§‹åŒ–çº¿ç¨‹"""
                nonlocal streaming_callback
                streaming_callback = create_streaming_callback("ğŸ–¼ï¸ è§†è§‰åˆ†æ")
                rich_ready.set()  # é€šçŸ¥Richåˆå§‹åŒ–å®Œæˆ
            
            def on_chunk(chunk: str):
                nonlocal total_chars, total_tokens_estimate, full_response, first_token_time
                
                # è®°å½•é¦–ä¸ªè¯çš„å“åº”æ—¶é—´ (TTFT - Time To First Token)
                if first_token_time is None and chunk.strip():
                    first_token_time = time.time()
                
                # ç´¯ç§¯å®Œæ•´å“åº”
                full_response += chunk
                
                # æ¸…ç†chunkï¼Œç§»é™¤ANSIé¢œè‰²ä»£ç è¿›è¡Œç»Ÿè®¡
                clean_chunk = re.sub(r'\x1b\[[0-9;]*m', '', chunk)
                total_chars += len(clean_chunk)
                # ç²—ç•¥ä¼°ç®—tokenæ•°ï¼ˆä¸­æ–‡çº¦2å­—ç¬¦=1tokenï¼Œè‹±æ–‡çº¦4å­—ç¬¦=1tokenï¼‰
                chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', clean_chunk))
                english_chars = len(clean_chunk) - chinese_chars
                total_tokens_estimate += chinese_chars // 2 + english_chars // 4
                
                # ç­‰å¾…Richåˆå§‹åŒ–å®Œæˆå†æ˜¾ç¤º
                rich_ready.wait()
                streaming_callback(chunk)
                time.sleep(self.config.stream_delay)

            # å¹¶è¡Œå¯åŠ¨ï¼šRichåˆå§‹åŒ–
            rich_thread = threading.Thread(target=init_rich)
            rich_thread.start()
            
            # ç«‹å³å‘é€APIè¯·æ±‚ï¼ˆä¸ç­‰Richåˆå§‹åŒ–ï¼‰
            api_start_time = time.time()
            result = self.client.chat_with_scenario(prompt, "vision", on_chunk, image_base64=image_base64)
            
            # ç­‰å¾…Richçº¿ç¨‹å®Œæˆ
            rich_thread.join()
            
            # å®Œæˆæµå¼è¾“å‡º
            if streaming_callback:
                streaming_callback.finish()
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            end_time = time.time()
            duration = end_time - api_start_time if api_start_time else 0
            chars_per_sec = total_chars / duration if duration > 0 else 0
            tokens_per_sec = total_tokens_estimate / duration if duration > 0 else 0
            
            # è®¡ç®—é¦–è¯å“åº”æ—¶é—´ (TTFT)
            ttft = (first_token_time - api_start_time) if (first_token_time and api_start_time) else 0
            
            if result:
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ï¼ŒåŒ…å«é¦–è¯å“åº”æ—¶é—´
                stats = {
                    "chars": total_chars,
                    "tokens": total_tokens_estimate,
                    "speed": chars_per_sec,
                    "token_speed": tokens_per_sec,
                    "ttft": ttft,  # Time To First Token
                    "duration": duration
                }
                display_statistics(stats)
            else:
                print_error("è·å–è§†è§‰åˆ†æå¤±è´¥")

        except AIClientError as e:
            print_error(f"è§†è§‰å¯¹è¯å¤±è´¥: {e}")
        except Exception as e:
            print_error(f"æœªçŸ¥é”™è¯¯: {e}")
    
    def _chat_with_vision_batch(self, prompt: str, image_base64: str) -> None:
        """æ‰¹é‡æ¨¡å¼è§†è§‰å¯¹è¯ - Richå¢å¼ºç‰ˆ"""
        print_info("ğŸ–¼ï¸ Qwen-VL æ­£åœ¨åˆ†æå›¾ç‰‡...")
        start_time = time.time()
        
        try:
            result = self.client.chat_with_scenario(prompt, "vision", image_base64=image_base64)
        except Exception as e:
            print_error(f"è§†è§‰åˆ†æå¤±è´¥: {e}")
            return
        
        end_time = time.time()
        duration = end_time - start_time

        if result:
            # ä½¿ç”¨Richæ˜¾ç¤ºAIå›å¤
            display_ai_response(result, "ğŸ–¼ï¸ è§†è§‰åˆ†æ")
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_chars = len(result)
            chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', result))
            english_chars = total_chars - chinese_chars
            total_tokens_estimate = chinese_chars // 2 + english_chars // 4
            
            stats = {
                "chars": total_chars,
                "tokens": total_tokens_estimate,
                "duration": duration
            }
            display_statistics(stats)
        else:
            print_error("è·å–è§†è§‰åˆ†æå¤±è´¥")


def main():
    parser = argparse.ArgumentParser(
        description="AIåŠ©æ‰‹å·¥å…· - æ”¯æŒå¤šç§è¾“å…¥æ–¹å¼",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹ï¼š
  %(prog)s chat "ä½ çš„é—®é¢˜"                    # åŸºç¡€ç”¨æ³•
  %(prog)s chat --interactive               # äº¤äº’æ¨¡å¼ï¼Œé¿å…ç‰¹æ®Šå­—ç¬¦é—®é¢˜
  %(prog)s chat --file question.txt        # ä»æ–‡ä»¶è¯»å–é—®é¢˜
  %(prog)s generate "æ–‡ç« æ ‡é¢˜"
  %(prog)s commit "æ›´æ”¹æ‘˜è¦"

æ³¨æ„ï¼šå¦‚æœé—®é¢˜åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œå»ºè®®ä½¿ç”¨äº¤äº’æ¨¡å¼æˆ–æ–‡ä»¶æ¨¡å¼
        """
    )
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')

    # chatå‘½ä»¤
    chat_parser = subparsers.add_parser('chat', help='AIå¯¹è¯')
    chat_group = chat_parser.add_mutually_exclusive_group(required=True)
    chat_group.add_argument('question', nargs='?', help='è¦é—®çš„é—®é¢˜ï¼ˆå¯é€‰ï¼‰')
    chat_group.add_argument('-i', '--interactive', action='store_true', help='äº¤äº’æ¨¡å¼è¾“å…¥')
    chat_group.add_argument('-f', '--file', help='ä»æ–‡ä»¶è¯»å–é—®é¢˜')
    chat_parser.add_argument('-s', '--stream', action='store_true', help='å¯ç”¨æµå¼è¾“å‡º')
    chat_parser.add_argument('-p', '--prompt', help='è‡ªå®šä¹‰ Prompt')
    chat_parser.add_argument('--prompt-file', help='ä»æ–‡ä»¶è¯»å–è‡ªå®šä¹‰ Prompt')
    chat_parser.add_argument('--image', action='store_true', help='å¯ç”¨å›¾ç‰‡åˆ†ææ¨¡å¼ï¼ˆä»å‰ªè´´æ¿è·å–å›¾ç‰‡ï¼‰')

    # generateå‘½ä»¤
    gen_parser = subparsers.add_parser('generate', help='ç”Ÿæˆåšå®¢æ–‡ç« ')
    gen_parser.add_argument('title', help='æ–‡ç« æ ‡é¢˜')

    # commitå‘½ä»¤
    commit_parser = subparsers.add_parser('commit', help='ç”Ÿæˆcommitä¿¡æ¯')
    commit_parser.add_argument('changes', help='æ–‡ä»¶æ›´æ”¹æ‘˜è¦')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    ai = AIHelper()

    if args.command == 'chat':
        question = None
        custom_prompt = None

        # å¤„ç†é—®é¢˜è¾“å…¥
        if args.question:
            question = args.question
        elif args.interactive:
            question = ai.get_interactive_input()
        elif args.file:
            question = ai.read_question_from_file(args.file)

        # å¤„ç†è‡ªå®šä¹‰prompt
        if args.prompt:
            custom_prompt = args.prompt
        elif args.prompt_file:
            custom_prompt = ai.read_prompt_from_file(args.prompt_file)

        if question:
            if args.image:
                ai.chat_with_image(question, custom_prompt=custom_prompt)
            else:
                ai.chat(question, use_stream=args.stream, custom_prompt=custom_prompt)
        else:
            print_error("æœªæä¾›æœ‰æ•ˆçš„é—®é¢˜å†…å®¹")

    elif args.command == 'generate':
        result = ai.generate_blog_article(args.title)
        if result:
            rich_output.console.print(result)
    elif args.command == 'commit':
        result = ai.generate_commit_message(args.changes)
        if result:
            print(result)  # ç›´æ¥è¾“å‡ºçº¯æ–‡æœ¬ï¼Œä¾›å…¶ä»–è„šæœ¬è°ƒç”¨
        else:
            print_error("ç”Ÿæˆcommitä¿¡æ¯å¤±è´¥")


if __name__ == "__main__":
    main()